{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleaning Data XI - Removing Duplicates\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "wine_reviews = pd.read_csv('../../winemag-data-130k.csv')\n",
    "wine_reviews.rename(columns={'points': 'rating'}, inplace=True)\n",
    "\n",
    "# Using this DataFrame, drop the null values in the 'price' and 'country' columns. Then find the number of duplicates values in the 'title' column.\n",
    "\n",
    "wine_ratings = wine_reviews[['title', 'country', 'rating', 'price']]\n",
    "a = len(wine_ratings) # 129971 rows\n",
    "\n",
    "\n",
    "wine_ratings = wine_ratings.dropna(subset=['country', 'price'])\n",
    "b = len(wine_ratings) # 120916 rows\n",
    "\n",
    "dups = wine_ratings.duplicated(['title']).sum() # 10333 dups\n",
    "\n",
    "\n",
    "\n",
    "# Now, drop the duplicate rows in the 'title' column.\n",
    "\n",
    "wine_ratings = wine_ratings.drop_duplicates(['title'])\n",
    "c = len(wine_ratings) # 110583 rows\n",
    "\n",
    "\n",
    "\n",
    "# Print out these statements with the correct values for the blanks.\n",
    "\n",
    "print(f'{a-b} rows w. null values removed')\n",
    "# 9055 rows w. null values removed\n",
    "print(f'{b-c} duplicate rows removed')\n",
    "# 10333 duplicate rows removed\n",
    "print(f'{a-c} total rows removed')\n",
    "# 19388 total rows removed"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
